{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocky Moutain Mentors: Using OpenAI's API for ALICIA: Academic Learning and Institutional Coaching Intelligent Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook contains the code to run a demo showcasing our custom GPT for the Rocky Mountain Mentors cooproporation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, paths and setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivicha/Documents/rocky_mountain_mentors/data/rmm_corpus/resources.txt\n"
     ]
    }
   ],
   "source": [
    "# imports & configuration\n",
    "import os, pathlib, json, textwrap\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import faiss\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "load_dotenv()                           # grabs OPENAI_API_KEY from .env\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Path of the notebook’s parent folder …/rocky_mountain_mentors\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "CORPUS_PATH = PROJECT_ROOT / \"data\" / \"rmm_corpus\" / \"resources.txt\"\n",
    "print(CORPUS_PATH)          # sanity-check\n",
    "assert CORPUS_PATH.exists(), f\"{CORPUS_PATH} not found.\"\n",
    "\n",
    "AGENT_DESC_PATH = PROJECT_ROOT / \"data\" / \"rmm_corpus\" / \"agent_description.txt\"\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-small\"  # fast & inexpensive; switch if needed\n",
    "TOKENIZER = tiktoken.encoding_for_model(\"gpt-4o\")  # for length management\n",
    "MAX_TOKENS_CONTEXT = 3000               # adjust for your target model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & embed the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 passages.\n"
     ]
    }
   ],
   "source": [
    "#  read the corpus and split into passages\n",
    "raw_text = CORPUS_PATH.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# naive split by double-newline; you can swap in langchain text splitters later\n",
    "passages = [p.strip() for p in raw_text.split(\"\\n\\n\") if p.strip()]\n",
    "print(f\"Loaded {len(passages)} passages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index ready: 1 vectors\n"
     ]
    }
   ],
   "source": [
    "# embed passages and build a FAISS index (runs once; cache if large)\n",
    "def embed(texts):\n",
    "    resp = openai.embeddings.create(model=EMBED_MODEL, input=texts)\n",
    "    return np.array([d.embedding for d in resp.data], dtype=\"float32\")\n",
    "\n",
    "emb_vectors = embed(passages)\n",
    "index = faiss.IndexFlatIP(emb_vectors.shape[1])\n",
    "index.add(emb_vectors)\n",
    "\n",
    "print(\"FAISS index ready:\", index.ntotal, \"vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv found at: /Users/ivicha/Documents/rocky_mountain_mentors/notebooks/.env\n",
      "Key length: 164\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "print(\"dotenv found at:\", find_dotenv())   # should show the absolute path\n",
    "\n",
    "load_dotenv(find_dotenv())                 # explicit path, avoids guesswork\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Key length:\", len(key) if key else key)\n",
    "assert key and key.startswith(\"sk-\"), \"OPENAI_API_KEY is missing or malformed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Retrieval helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic search\n",
    "def retrieve(query, k=4):\n",
    "    q_vec = embed([query])[0].reshape(1, -1)\n",
    "    scores, idxs = index.search(q_vec, k)\n",
    "    return [(passages[i], float(scores[0][j])) for j, i in enumerate(idxs[0])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt & conversation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded system prompt – 228 words\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_DESC = AGENT_DESC_PATH.read_text(encoding=\"utf-8\").strip()\n",
    "print(\"Loaded system prompt –\", len(SYSTEM_DESC.split()), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "# ---------- 1) persistent memory ---------- #\n",
    "student_profile = {}          # cleared each time you restart the process\n",
    "conversation    = []          # running message list\n",
    "\n",
    "def parse_student_info(text):\n",
    "    \"\"\"\n",
    "    Very simple heuristic:\n",
    "      • program keywords PhD|MS|Bachelor\n",
    "      • year = 1–6  (or words like freshman, sophomore...)\n",
    "    Modify as needed!\n",
    "    \"\"\"\n",
    "    prog = None\n",
    "    year = None\n",
    "\n",
    "    program_match = re.search(r\"\\b(PhD|PHD|MS|M\\.?S\\.?|Bachelor'?s?)\\b\", text, re.I)\n",
    "    if program_match:\n",
    "        prog = program_match.group(1).upper().replace(\".\", \"\")\n",
    "        if prog.startswith(\"B\"):\n",
    "            prog = \"Bachelor's\"\n",
    "\n",
    "    # numeric year\n",
    "    year_match = re.search(r\"\\b([1-6])(?:st|nd|rd|th)?\\s*year\\b\", text, re.I)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "    else:\n",
    "        # common words\n",
    "        words = {\"freshman\":1,\"sophomore\":2,\"junior\":3,\"senior\":4}\n",
    "        for w,n in words.items():\n",
    "            if w in text.lower():\n",
    "                year = n\n",
    "                break\n",
    "    return prog, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(user_message):\n",
    "    # 1️⃣ base & personalization\n",
    "    sys_base = {\"role\": \"system\", \"content\": SYSTEM_DESC}\n",
    "\n",
    "    if student_profile:\n",
    "        sys_personal = {\"role\": \"system\",\n",
    "                        \"content\": f\"Student program: {student_profile['program']}, \"\n",
    "                                   f\"Year: {student_profile['year']}.\"}\n",
    "    else:\n",
    "        sys_personal = {\"role\": \"system\",\n",
    "                        \"content\": (\"Ask once for program + year, then remember.\")}\n",
    "\n",
    "    # 2️⃣ embed retrieval\n",
    "    docs = retrieve(user_message, k=5)\n",
    "    context = \"\\n\\n\".join(f\"{i+1}. {d[0]}\" for i, d in enumerate(docs))\n",
    "\n",
    "    # 3️⃣ hard rule + context wrapped together\n",
    "    assistant_context = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"**Grounding data – you MUST base your answer ONLY on these excerpts. \"\n",
    "            \"If they don’t contain the answer, reply 'I don’t have that information, but I searched online and found {then search online and find a reliable source like the program website, find the anwert and return the answer AND your source link}.'**\\n\\n\"\n",
    "            + context)\n",
    "    }\n",
    "\n",
    "    # 4️⃣ assemble (context is *immediately* before user)\n",
    "    return [sys_base, sys_personal] + conversation + [\n",
    "            assistant_context,\n",
    "            {\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "def chat(user_message, model=\"gpt-4o-mini\"):\n",
    "    global student_profile, conversation\n",
    "\n",
    "    # send the prompt\n",
    "    messages = build_prompt(user_message)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        max_tokens=512,\n",
    "    ).choices[0].message.content.strip()\n",
    "\n",
    "    # 4) If we have no profile yet, try to parse it from the *user* message\n",
    "    if not student_profile:\n",
    "        prog, yr = parse_student_info(user_message)\n",
    "        if prog and yr:\n",
    "            student_profile = {\"program\": prog, \"year\": yr}\n",
    "\n",
    "    # 5) Append turn to running conversation\n",
    "    conversation.extend([\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "    ])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have that information. Could you please tell me what program you are in (PhD, MS, or Bachelor's) and what year you are currently in?\n",
      "Great! As a second-year MS student, you might be focusing on your coursework, research, and possibly preparing for your thesis or capstone project. If you have any specific questions about program requirements, mentorship, professional development, or community building, feel free to ask!\n",
      "You need to pass all classes with a minimum GPA of 2 to graduate. If you have any more questions about your program or requirements, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "conversation.clear()\n",
    "student_profile.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "# ---------- 1) persistent memory ---------- #\n",
    "student_profile = {}          # cleared each time you restart the process\n",
    "conversation    = []          # running message list\n",
    "\n",
    "def parse_student_info(text):\n",
    "    \"\"\"\n",
    "    Very simple heuristic:\n",
    "      • program keywords PhD|MS|Bachelor\n",
    "      • year = 1–6  (or words like freshman, sophomore...)\n",
    "    Modify as needed!\n",
    "    \"\"\"\n",
    "    prog = None\n",
    "    year = None\n",
    "\n",
    "    program_match = re.search(r\"\\b(PhD|PHD|MS|M\\.?S\\.?|Bachelor'?s?)\\b\", text, re.I)\n",
    "    if program_match:\n",
    "        prog = program_match.group(1).upper().replace(\".\", \"\")\n",
    "        if prog.startswith(\"B\"):\n",
    "            prog = \"Bachelor's\"\n",
    "\n",
    "    # numeric year\n",
    "    year_match = re.search(r\"\\b([1-6])(?:st|nd|rd|th)?\\s*year\\b\", text, re.I)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "    else:\n",
    "        # common words\n",
    "        words = {\"freshman\":1,\"sophomore\":2,\"junior\":3,\"senior\":4}\n",
    "        for w,n in words.items():\n",
    "            if w in text.lower():\n",
    "                year = n\n",
    "                break\n",
    "    return prog, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal Tkinter front-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Rocky Mountain Mentor UI (logo bigger, new banner text)\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "from tkinter import font as tkfont\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "\n",
    "# ───────────── Palette ─────────────\n",
    "HEADER_BG = \"#3c6834\"   # soft green\n",
    "WINDOW_BG = \"#c5b78a\"   # light gold\n",
    "CHAT_BG   = \"#f9f5e9\"   # creamy off-white\n",
    "USER_BG   = \"#c5b78a\"\n",
    "BOT_BG    = \"#496d96\"\n",
    "ACCENT    = \"#a46d5e\"\n",
    "TEXT_DARK = \"#000000\"\n",
    "TEXT_LIGHT= \"#ffffff\"\n",
    "\n",
    "# ───────────── Root window ─────────────\n",
    "root = tk.Tk()\n",
    "root.title(\"Rocky Mountain Mentors 2025\")\n",
    "root.configure(bg=WINDOW_BG)\n",
    "root.geometry(\"900x650\")\n",
    "\n",
    "# ───────────── Font selection (after root exists) ─────────────\n",
    "available_fonts = set(tkfont.families(root))\n",
    "base_font = (\"SF Pro Text\" if \"SF Pro Text\" in available_fonts\n",
    "             else \"Helvetica Neue\" if \"Helvetica Neue\" in available_fonts\n",
    "             else \"Helvetica\")\n",
    "SYSTEM_FONT = (base_font, 13)\n",
    "TITLE_FONT  = (base_font, 26, \"bold\")\n",
    "\n",
    "# ───────────── ttk styling ─────────────\n",
    "style = ttk.Style(root)\n",
    "style.theme_use(\"clam\")\n",
    "style.configure(\"TFrame\",  background=WINDOW_BG)\n",
    "style.configure(\"Header.TFrame\", background=HEADER_BG)\n",
    "style.configure(\"TButton\", background=ACCENT, foreground=TEXT_LIGHT,\n",
    "                font=SYSTEM_FONT, borderwidth=0)\n",
    "style.map(\"TButton\",\n",
    "          background=[(\"active\", HEADER_BG), (\"pressed\", HEADER_BG)])\n",
    "\n",
    "# ───────────── Header (logo + title) ─────────────\n",
    "# ───────────── Header (slim bar w/ big logo) ─────────────\n",
    "HEADER_HEIGHT = 50                            # exact green-bar height\n",
    "header = ttk.Frame(root, style=\"Header.TFrame\", height=HEADER_HEIGHT)\n",
    "header.pack(fill=\"x\", pady=(4, 3))\n",
    "header.pack_propagate(False)                     # prevent auto-expansion\n",
    "\n",
    "LOGO_W = 75                                    # logo is wide\n",
    "logo_path = Path.cwd().parent / \"data\" / \"RMM_logo_cropped.png\"\n",
    "if logo_path.exists():\n",
    "    # Resize keeping aspect ratio; the image height may exceed HEADER_HEIGHT,\n",
    "    # which is fine—the frame will crop it vertically.\n",
    "    logo_img = Image.open(logo_path)\n",
    "    w_percent = LOGO_W / float(logo_img.width)\n",
    "    new_size = (LOGO_W, int(logo_img.height * w_percent))\n",
    "    logo_img = logo_img.resize(new_size, Image.LANCZOS)\n",
    "    logo_photo = ImageTk.PhotoImage(logo_img)\n",
    "    tk.Label(header, image=logo_photo, bg=HEADER_BG)\\\n",
    "      .pack(side=\"left\", padx=10)\n",
    "\n",
    "TITLE_FONT = (base_font, 20, \"bold\")\n",
    "tk.Label(header, text=\"ALICIA: Academic Learning and Institutional Coaching Intelligent Assistant\", font=TITLE_FONT,\n",
    "         bg=HEADER_BG, fg=TEXT_DARK)\\\n",
    "  .pack(side=\"left\", padx=(0, 0))\n",
    "\n",
    "# ───────────── Chat area ─────────────\n",
    "chat_frame = ttk.Frame(root)\n",
    "chat_frame.pack(fill=\"both\", expand=True, padx=15, pady=6)\n",
    "\n",
    "chat_log = ScrolledText(chat_frame, wrap=\"word\", state=\"normal\",\n",
    "                        bg=CHAT_BG, fg=TEXT_DARK, font=SYSTEM_FONT,\n",
    "                        borderwidth=0, relief=\"flat\")\n",
    "chat_log.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# Bubble tags\n",
    "chat_log.tag_configure(\"user\", background=USER_BG, foreground=TEXT_DARK,\n",
    "                       lmargin1=8, lmargin2=8, rmargin=8)\n",
    "chat_log.tag_configure(\"bot\",  background=BOT_BG,  foreground=TEXT_LIGHT,\n",
    "                       lmargin1=8, lmargin2=8, rmargin=8)\n",
    "chat_log.tag_configure(\"bubble_wrap\", spacing1=5, spacing3=5)\n",
    "\n",
    "# Intro banner\n",
    "intro = (\"Hi, I'm ALICIA. Here to help! Ask me anything about the \"\n",
    "         \"program, mentorship, resources, and more. How can I help you today?\")\n",
    "chat_log.insert(tk.END, f\"╭──\\n{intro}\\n╰──\\n\", (\"bot\", \"bubble_wrap\"))\n",
    "chat_log.configure(state=\"disabled\")    # lock it before normal use\n",
    "\n",
    "# ───────────── Entry & send button ─────────────\n",
    "input_frame = ttk.Frame(root)\n",
    "input_frame.pack(fill=\"x\", padx=15, pady=(0, 15))\n",
    "\n",
    "entry = tk.Text(input_frame, font=SYSTEM_FONT, height=2, wrap=\"word\",\n",
    "                relief=\"flat\", highlightthickness=1, highlightbackground=\"#aaaaaa\")\n",
    "entry.pack(side=\"left\", fill=\"x\", expand=True, pady=3)\n",
    "\n",
    "def send_query():\n",
    "    user_msg = entry.get(\"1.0\", \"end-1c\").strip()\n",
    "    if not user_msg:\n",
    "        return\n",
    "    entry.delete(\"1.0\", tk.END)\n",
    "\n",
    "    def insert_bubble(text, tag):\n",
    "        chat_log.configure(state=\"normal\")\n",
    "        chat_log.insert(tk.END, f\"╭──\\n{text}\\n╰──\\n\", (tag, \"bubble_wrap\"))\n",
    "        chat_log.configure(state=\"disabled\")\n",
    "        chat_log.see(tk.END)\n",
    "\n",
    "    insert_bubble(user_msg, \"user\")\n",
    "\n",
    "    def worker():\n",
    "        try:\n",
    "            bot_reply = chat(user_msg)\n",
    "        except Exception as e:\n",
    "            bot_reply = f\"[Error] {e}\"\n",
    "        insert_bubble(bot_reply, \"bot\")\n",
    "    threading.Thread(target=worker, daemon=True).start()\n",
    "\n",
    "ttk.Button(input_frame, text=\"Send\", command=send_query)\\\n",
    "   .pack(side=\"right\", padx=(12, 0), ipadx=10, ipady=6)\n",
    "\n",
    "entry.bind(\"<Return>\", lambda e: send_query())\n",
    "\n",
    "# ───────────── Launch ─────────────\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rmm-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
