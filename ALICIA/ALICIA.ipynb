{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocky Moutain Mentors: Using OpenAI's API for ALICIA: Academic Learning and Institutional Coaching Intelligent Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook contains the code to run a demo showcasing our custom GPT for the Rocky Mountain Mentors cooproporation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, paths and setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivicha/Documents/rocky_mountain_mentors/data/rmm_corpus/resources.txt\n"
     ]
    }
   ],
   "source": [
    "# imports & configuration\n",
    "import os, pathlib, json, textwrap\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import tiktoken\n",
    "import faiss\n",
    "import numpy as np\n",
    "import markdown, re\n",
    "from pathlib import Path\n",
    "from tkhtmlview import HTMLScrolledText     # instead of HTMLLabel\n",
    "import datetime as dt\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "from tkinter import font as tkfont\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "\n",
    "load_dotenv()                           # grabs OPENAI_API_KEY from .env\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Path of the notebook’s parent folder …/rocky_mountain_mentors\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "CORPUS_PATH = PROJECT_ROOT / \"data\" / \"rmm_corpus\" / \"resources.txt\"\n",
    "print(CORPUS_PATH)          # sanity-check\n",
    "assert CORPUS_PATH.exists(), f\"{CORPUS_PATH} not found.\"\n",
    "\n",
    "AGENT_DESC_PATH = PROJECT_ROOT / \"data\" / \"rmm_corpus\" / \"agent_description.txt\"\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-small\"  # fast & inexpensive; switch if needed\n",
    "TOKENIZER = tiktoken.encoding_for_model(\"gpt-4o\")  # for length management\n",
    "MAX_TOKENS_CONTEXT = 3000               # adjust for your target model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & embed the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 passages.\n"
     ]
    }
   ],
   "source": [
    "#  read the corpus and split into passages\n",
    "raw_text = CORPUS_PATH.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# naive split by double-newline; you can swap in langchain text splitters later\n",
    "passages = [p.strip() for p in raw_text.split(\"\\n\\n\") if p.strip()]\n",
    "print(f\"Loaded {len(passages)} passages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index ready: 1 vectors\n"
     ]
    }
   ],
   "source": [
    "# embed passages and build a FAISS index (runs once; cache if large)\n",
    "def embed(texts):\n",
    "    resp = openai.embeddings.create(model=EMBED_MODEL, input=texts)\n",
    "    return np.array([d.embedding for d in resp.data], dtype=\"float32\")\n",
    "\n",
    "emb_vectors = embed(passages)\n",
    "index = faiss.IndexFlatIP(emb_vectors.shape[1])\n",
    "index.add(emb_vectors)\n",
    "\n",
    "print(\"FAISS index ready:\", index.ntotal, \"vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv found at: /Users/ivicha/Documents/rocky_mountain_mentors/ALICIA/.env\n",
      "Key length: 164\n"
     ]
    }
   ],
   "source": [
    "print(\"dotenv found at:\", find_dotenv())   # should show the absolute path\n",
    "\n",
    "load_dotenv(find_dotenv())                 # explicit path, avoids guesswork\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Key length:\", len(key) if key else key)\n",
    "assert key and key.startswith(\"sk-\"), \"OPENAI_API_KEY is missing or malformed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Retrieval helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic search\n",
    "def retrieve(query, k=4):\n",
    "    q_vec = embed([query])[0].reshape(1, -1)\n",
    "    scores, idxs = index.search(q_vec, k)\n",
    "    return [(passages[i], float(scores[0][j])) for j, i in enumerate(idxs[0])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System prompt & conversation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded system prompt – 286 words\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_DESC = AGENT_DESC_PATH.read_text(encoding=\"utf-8\").strip()\n",
    "print(\"Loaded system prompt –\", len(SYSTEM_DESC.split()), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1) persistent memory ---------- #\n",
    "student_profile = {}          # cleared each time you restart the process\n",
    "conversation    = []          # running message list\n",
    "\n",
    "def parse_student_info(text):\n",
    "    \"\"\"\n",
    "    Very simple heuristic:\n",
    "      • program keywords PhD|MS|Bachelor\n",
    "      • year = 1–6  (or words like freshman, sophomore...)\n",
    "    Modify as needed!\n",
    "    \"\"\"\n",
    "    prog = None\n",
    "    year = None\n",
    "\n",
    "    program_match = re.search(r\"\\b(PhD|PHD|MS|M\\.?S\\.?|Bachelor'?s?)\\b\", text, re.I)\n",
    "    if program_match:\n",
    "        prog = program_match.group(1).upper().replace(\".\", \"\")\n",
    "        if prog.startswith(\"B\"):\n",
    "            prog = \"Bachelor's\"\n",
    "\n",
    "    # numeric year\n",
    "    year_match = re.search(r\"\\b([1-6])(?:st|nd|rd|th)?\\s*year\\b\", text, re.I)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "    else:\n",
    "        # common words\n",
    "        words = {\"freshman\":1,\"sophomore\":2,\"junior\":3,\"senior\":4}\n",
    "        for w,n in words.items():\n",
    "            if w in text.lower():\n",
    "                year = n\n",
    "                break\n",
    "    return prog, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(user_message):\n",
    "    # 1️⃣ base & personalization\n",
    "    sys_base = {\"role\": \"system\", \"content\": SYSTEM_DESC}\n",
    "\n",
    "    if student_profile:\n",
    "        sys_personal = {\"role\": \"system\",\n",
    "                        \"content\": f\"Student program: {student_profile['program']}, \"\n",
    "                                   f\"Year: {student_profile['year']}.\"}\n",
    "    else:\n",
    "        sys_personal = {\"role\": \"system\",\n",
    "                        \"content\": (\"Ask once for program + year, then remember.\")}\n",
    "\n",
    "    # 2️⃣ embed retrieval\n",
    "    docs = retrieve(user_message, k=5)\n",
    "    context = \"\\n\\n\".join(f\"{i+1}. {d[0]}\" for i, d in enumerate(docs))\n",
    "\n",
    "    # 3️⃣ hard rule + context wrapped together\n",
    "    assistant_context = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": (\n",
    "            \"**Grounding data – you MUST base your answer ONLY on these excerpts. \"\n",
    "            \"If they don’t contain the answer, reply 'I don’t have that information, but I searched online and found {then search online and find a reliable source like the program website, find the answer and return the answer AND your source link}. Everything should be specific to the University of Colorado Anschutz Medical Campus and Denver campus, as well as the student's current program and year.'**\\n\\n\"\n",
    "            + context)\n",
    "    }\n",
    "\n",
    "    # 4️⃣ assemble (context is *immediately* before user)\n",
    "    return [sys_base, sys_personal] + conversation + [\n",
    "            assistant_context,\n",
    "            {\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "def chat(user_message, model=\"gpt-4o-mini\"):\n",
    "    global student_profile, conversation\n",
    "\n",
    "    # send the prompt\n",
    "    messages = build_prompt(user_message)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        max_tokens=512,\n",
    "    ).choices[0].message.content.strip()\n",
    "\n",
    "    # 4) If we have no profile yet, try to parse it from the *user* message\n",
    "    if not student_profile:\n",
    "        prog, yr = parse_student_info(user_message)\n",
    "        if prog and yr:\n",
    "            student_profile = {\"program\": prog, \"year\": yr}\n",
    "\n",
    "    # 5) Append turn to running conversation\n",
    "    conversation.extend([\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "    ])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.clear()\n",
    "student_profile.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---------- 1) persistent memory ---------- #\n",
    "student_profile = {}          # cleared each time you restart the process\n",
    "conversation    = []          # running message list\n",
    "\n",
    "def parse_student_info(text):\n",
    "    \"\"\"\n",
    "    Very simple heuristic:\n",
    "      • program keywords PhD|MS|Bachelor\n",
    "      • year = 1–6  (or words like freshman, sophomore...)\n",
    "    Modify as needed!\n",
    "    \"\"\"\n",
    "    prog = None\n",
    "    year = None\n",
    "\n",
    "    program_match = re.search(r\"\\b(PhD|PHD|MS|M\\.?S\\.?|Bachelor'?s?)\\b\", text, re.I)\n",
    "    if program_match:\n",
    "        prog = program_match.group(1).upper().replace(\".\", \"\")\n",
    "        if prog.startswith(\"B\"):\n",
    "            prog = \"Bachelor's\"\n",
    "\n",
    "    # numeric year\n",
    "    year_match = re.search(r\"\\b([1-6])(?:st|nd|rd|th)?\\s*year\\b\", text, re.I)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(1))\n",
    "    else:\n",
    "        # common words\n",
    "        words = {\"freshman\":1,\"sophomore\":2,\"junior\":3,\"senior\":4}\n",
    "        for w,n in words.items():\n",
    "            if w in text.lower():\n",
    "                year = n\n",
    "                break\n",
    "    return prog, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal Tkinter front-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────── Palette ─────────────\n",
    "HEADER_BG = \"#3c6834\"   # soft green\n",
    "WINDOW_BG = \"#c5b78a\"   # light gold\n",
    "CHAT_BG   = \"#f9f5e9\"   # creamy off-white\n",
    "USER_BG = \"#e9dfba\"\n",
    "BOT_BG    = \"#f9f5e9\" \n",
    "ACCENT    = \"#a46d5e\"\n",
    "TEXT_DARK = \"#000000\"\n",
    "TEXT_LIGHT= \"#ffffff\"\n",
    "\n",
    "# ───────────── Root window ─────────────\n",
    "root = tk.Tk()\n",
    "root.title(\"Rocky Mountain Mentors (2025)\")\n",
    "root.configure(bg=WINDOW_BG)\n",
    "root.geometry(\"910x650\")\n",
    "\n",
    "# ───────────── Font selection (after root exists) ─────────────\n",
    "available_fonts = set(tkfont.families(root))\n",
    "base_font = (\"SF Pro Text\" if \"SF Pro Text\" in available_fonts\n",
    "             else \"Helvetica Neue\" if \"Helvetica Neue\" in available_fonts\n",
    "             else \"Helvetica\")\n",
    "SYSTEM_FONT = (base_font, 13)\n",
    "TITLE_FONT  = (base_font, 26, \"bold\")\n",
    "\n",
    "# ───────────── ttk styling ─────────────\n",
    "style = ttk.Style(root)\n",
    "style.theme_use(\"clam\")\n",
    "style.configure(\"TFrame\",  background=WINDOW_BG)\n",
    "style.configure(\"Header.TFrame\", background=HEADER_BG)\n",
    "style.configure(\"TButton\", background=ACCENT, foreground=TEXT_LIGHT,\n",
    "                font=SYSTEM_FONT, borderwidth=0)\n",
    "style.map(\"TButton\",\n",
    "          background=[(\"active\", HEADER_BG), (\"pressed\", HEADER_BG)])\n",
    "\n",
    "# ───────────── Header (logo + title) ─────────────\n",
    "# ───────────── Header (slim bar w/ big logo) ─────────────\n",
    "HEADER_HEIGHT = 50                            # exact green-bar height\n",
    "header = ttk.Frame(root, style=\"Header.TFrame\", height=HEADER_HEIGHT)\n",
    "header.pack(fill=\"x\", pady=(4, 3))\n",
    "header.pack_propagate(False)                     # prevent auto-expansion\n",
    "\n",
    "LOGO_W = 75                                    # logo is wide\n",
    "logo_path = Path.cwd().parent / \"data\" / \"RMM_logo_cropped.png\"\n",
    "if logo_path.exists():\n",
    "    # Resize keeping aspect ratio; the image height may exceed HEADER_HEIGHT,\n",
    "    # which is fine—the frame will crop it vertically.\n",
    "    logo_img = Image.open(logo_path)\n",
    "    w_percent = LOGO_W / float(logo_img.width)\n",
    "    new_size = (LOGO_W, int(logo_img.height * w_percent))\n",
    "    logo_img = logo_img.resize(new_size, Image.LANCZOS)\n",
    "    logo_photo = ImageTk.PhotoImage(logo_img)\n",
    "    tk.Label(header, image=logo_photo, bg=HEADER_BG)\\\n",
    "      .pack(side=\"left\", padx=20)\n",
    "\n",
    "TITLE_FONT = (base_font, 20, \"bold\")\n",
    "tk.Label(header, text=\"ALICIA: Academic Learning and Institutional Coaching Intelligent Assistant\", font=TITLE_FONT,\n",
    "         bg=HEADER_BG, fg=TEXT_DARK)\\\n",
    "  .pack(side=\"left\", padx=(0, 1))\n",
    "\n",
    "# ───────────── Chat area ─────────────\n",
    "\n",
    "chat_frame = ttk.Frame(root)\n",
    "chat_frame.pack(fill=\"both\", expand=True, padx=15, pady=6)\n",
    "\n",
    "chat_log = HTMLScrolledText(                # Markdown-aware widget\n",
    "    chat_frame,\n",
    "    html=\"\",                                # start empty\n",
    "    background=CHAT_BG,                     # overall chat bg\n",
    "    font=SYSTEM_FONT,\n",
    "    fg=TEXT_DARK,\n",
    "    relief=\"flat\", bd=0, width=150\n",
    ")\n",
    "chat_log.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# keep the whole transcript as one HTML string\n",
    "conversation_html = \"\"\n",
    "transcript = []          # list of tuples: (tag, md_text)\n",
    "def insert_bubble(md_text: str, tag: str):\n",
    "    transcript.append((tag, md_text))          # store raw data\n",
    "\n",
    "    # ── rebuild the entire document every time ──\n",
    "    doc = \"\"\n",
    "    for who, md in transcript:\n",
    "        doc += _one_bubble_html(md, who)       # call helper that returns HTML\n",
    "\n",
    "    chat_log.set_html(doc)\n",
    "    chat_log.yview_moveto(1.0)\n",
    "\n",
    "MAX_W      = \"60%\"\n",
    "PAD_USER   = \"8px 10px\"\n",
    "GAP_USER   = \"8px\"\n",
    "GAP_BOT    = \"3px\"\n",
    "\n",
    "def _one_bubble_html(md_text: str, tag: str) -> str:\n",
    "    html = markdown.markdown(md_text,\n",
    "                             extensions=[\"fenced_code\", \"tables\", \"nl2br\"])\n",
    "    html = re.sub(r\"</?p[^>]*>\", \"\", html, flags=re.S).replace(\"<br>\", \"\")\n",
    "\n",
    "    if tag == \"user\":\n",
    "        return (\n",
    "            #  ▼ overflow:auto ⇒ new BFC ⇒ margins no longer collapse\n",
    "            f'<div style=\"margin:{GAP_USER} 0; overflow:auto;\">'\n",
    "            f'  <div style=\"text-align:right;\">'\n",
    "            f'    <span style=\"background-color:{USER_BG}; color:{TEXT_DARK}; '\n",
    "            f'          padding:{PAD_USER}; border-radius:10px; '\n",
    "            f'          display:inline-block; max-width:{MAX_W}; '\n",
    "            f'          font-family:{base_font}; font-size:15px; '\n",
    "            f'          line-height:1.35;\">{html}</span>'\n",
    "            f'  </div>'\n",
    "            f'</div>'\n",
    "        )\n",
    "\n",
    "    # bot branch (unchanged)\n",
    "    return (\n",
    "        f'<div style=\"padding:{GAP_BOT} 0; text-align:left; '\n",
    "        f'            max-width:{MAX_W}; font-family:{base_font}; '\n",
    "        f'            font-size:15px; line-height:1.35; color:{TEXT_DARK};\">'\n",
    "        f'{html}</div>'\n",
    "    )\n",
    "\n",
    "# Intro banner (first bot bubble)\n",
    "intro = (\"Hi, I'm ALICIA. Here to help! Ask me anything about the \"\n",
    "         \"program, mentorship, resources, and more. How can I help you today?\")\n",
    "\n",
    "insert_bubble(intro, \"bot\")\n",
    "\n",
    "# ───────────── Entry & send button ─────────────\n",
    "input_frame = ttk.Frame(root)\n",
    "input_frame.pack(fill=\"x\", padx=15, pady=(0, 15))\n",
    "\n",
    "entry = tk.Text(input_frame, font=SYSTEM_FONT, height=2, wrap=\"word\",\n",
    "                relief=\"flat\", highlightthickness=1, highlightbackground=\"#aaaaaa\")\n",
    "entry.pack(side=\"left\", fill=\"x\", expand=True, pady=3)\n",
    "\n",
    "def send_query():\n",
    "    user_msg = entry.get(\"1.0\", \"end-1c\").strip()\n",
    "    if not user_msg:\n",
    "        return\n",
    "    entry.delete(\"1.0\", tk.END)\n",
    "\n",
    "    insert_bubble(user_msg, \"user\")   # show the user’s text immediately\n",
    "\n",
    "    def worker():\n",
    "        try:\n",
    "            bot_reply = chat(user_msg)      # your LLM function\n",
    "        except Exception as e:\n",
    "            bot_reply = f\"[Error] {e}\"\n",
    "        # update GUI safely from the main thread\n",
    "        root.after(0, lambda: insert_bubble(bot_reply, \"bot\"))\n",
    "\n",
    "    threading.Thread(target=worker, daemon=True).start()\n",
    "\n",
    "ttk.Button(input_frame, text=\"Send\", command=send_query)\\\n",
    "   .pack(side=\"right\", padx=(12, 0), ipadx=10, ipady=6)\n",
    "\n",
    "def on_enter(event):\n",
    "    send_query()\n",
    "    return \"break\"        # prevents newline in the Text widget\n",
    "\n",
    "entry.bind(\"<Return>\", on_enter)\n",
    "\n",
    "# ───────────── Launch ─────────────\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rmm-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
